{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "postags = [\"PROPN\", \"NOUN\", \"VERB\", \"ADJ\"]\n",
    "\n",
    "def clean_token(token):\n",
    "    token = re.sub(\"\\W\", \"\", token)\n",
    "    token = token[0] + token[1:].lower()\n",
    "    return token\n",
    "\n",
    "def doc_to_lemmata(doc, postags):\n",
    "    lemmata_list = [t.lemma_ for t in doc if t.pos_ in postags]\n",
    "    lemmata_list = [clean_token(el) for el in lemmata_list if len(el)>0]\n",
    "    joined_lemmata_sorted = \" \".join(sorted(lemmata_list))\n",
    "    return joined_lemmata_sorted\n",
    "\n",
    "def ngram_to_lemmata(ngram, ngram_nlp_dict):\n",
    "    try:\n",
    "        lemmata_sorted_str = doc_to_lemmata(ngram_nlp_dict[ngram][\"doc\"], postags)\n",
    "        #print(\"found in preprocessed\") # (used for execution time tests...)\n",
    "    except:\n",
    "        try:\n",
    "            lemmata_sorted_str = doc_to_lemmata(nlp(ngram), postags)\n",
    "            # print(\"processed now\") # (used for execution time tests...)\n",
    "        except:\n",
    "            lemmata_sorted_str = \"\"\n",
    "    return lemmata_sorted_str\n",
    "\n",
    "def article_data_to_lemmata(ngrams_dict, ngram_nlp_dict):\n",
    "    lemmata_tups = []\n",
    "    for string, count in ngrams_dict.items():\n",
    "        lemmata_tups.append((ngram_to_lemmata(string, ngram_nlp_dict), count))\n",
    "    lemmata_tups = [tup for tup in lemmata_tups if len(tup[0]) > 1]\n",
    "    lemmata_dict = Counter()\n",
    "    for x,y in lemmata_tups:\n",
    "        lemmata_dict.update({x : y})\n",
    "    return lemmata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ngram_type = \"unigram\"\n",
    "ngramCount_dict = pickle.load(open(\"../data/large_files/{0}Count_dict.pickle\".format(ngram_type), \"rb\"))\n",
    "ngram_nlp_dict = pickle.load(open(\"../data/large_files/data_{0}s_nlp_dict.pickle\".format(ngram_type), \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 148 ms, sys: 35.1 ms, total: 184 ms\n",
      "Wall time: 191 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('child', 30),\n ('handicap', 18),\n ('street', 16),\n ('have', 11),\n ('city', 11),\n ('family', 10),\n ('life', 10),\n ('church', 9),\n ('Mexico', 9),\n ('work', 8),\n ('Christ', 8),\n ('feel', 8),\n ('syndrome', 7),\n ('education', 7),\n ('live', 6),\n ('home', 6),\n ('time', 6),\n ('physical', 6),\n ('ministry', 6),\n ('mexican', 6),\n ('God', 5),\n ('give', 5),\n ('parent', 5),\n ('social', 5),\n ('love', 4),\n ('need', 4),\n ('christian', 4),\n ('holy', 4),\n ('process', 4),\n ('gospel', 4),\n ('other', 4),\n ('people', 4),\n ('result', 3),\n ('society', 3),\n ('preach', 3),\n ('great', 3),\n ('programme', 3),\n ('centre', 3),\n ('government', 3),\n ('do', 3),\n ('day', 3),\n ('permit', 3),\n ('drug', 3),\n ('understand', 3),\n ('educational', 3),\n ('transformation', 3),\n ('man', 3),\n ('study', 3),\n ('serious', 3),\n ('career', 3),\n ('second', 3),\n ('most', 3),\n ('go', 3),\n ('scripture', 3),\n ('Jesus', 3),\n ('write', 3),\n ('reality', 3),\n ('environment', 3),\n ('situation', 3),\n ('faith', 3),\n ('involve', 3),\n ('attention', 3),\n ('urban', 3),\n ('power', 3),\n ('marginalise', 3),\n ('suffer', 3),\n ('special', 3),\n ('difficult', 3),\n ('deterioration', 2),\n ('mean', 2),\n ('search', 2),\n ('struggle', 2),\n ('act', 2),\n ('come', 2),\n ('such', 2),\n ('service', 2),\n ('creative', 2),\n ('normal', 2),\n ('share', 2),\n ('illness', 2),\n ('formation', 2),\n ('heart', 2),\n ('care', 2),\n ('cerebral', 2),\n ('aim', 2),\n ('Armando', 2),\n ('transform', 2),\n ('know', 2),\n ('condition', 2),\n ('system', 2),\n ('testimony', 2),\n ('girl', 2),\n ('bear', 2),\n ('truth', 2),\n ('restoration', 2),\n ('Raul', 2),\n ('vision', 2),\n ('individual', 2),\n ('brain', 2),\n ('forgiveness', 2)]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_ngrams_dict = (list(ngramCount_dict.items())[5000][1])\n",
    "test_output = article_data_to_lemmata(test_ngrams_dict, ngram_nlp_dict)\n",
    "sorted(test_output.items(), key=lambda pair: pair[1], reverse=True)[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 75.9 ms, total: 12.1 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 10\n",
    "cleanedNgrams_tups = []\n",
    "for k, v in list(ngramCount_dict.items())[:n]:\n",
    "    cleanedNgrams_tups.append((k, article_data_to_lemmata(v, ngram_nlp_dict)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "233.33333333333334"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 * 14000) / 60"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}